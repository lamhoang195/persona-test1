import math
from google import genai
from google.genai.types import GenerateContentConfig


class GeminiJudge:
    """
    Judge using Gemini via Vertex AI GenAI.
    Supports:
        - eval_type="0_100" â†’ dÃ¹ng logprobs Ä‘á»ƒ láº¥y phÃ¢n phá»‘i sá»‘ 0â€“100
    """

    def __init__(self, model: str, prompt_template: str, eval_type: str = "0_100"):
        self.model_name = model
        self.client = genai.Client(vertexai=True)
        self.prompt_template = prompt_template

        assert eval_type in ["0_100"], f"Unsupported eval_type: {eval_type}"
        self.eval_type = eval_type

        if self.eval_type == "0_100":
            self.aggregate_score = self._aggregate_0_100_score

    async def __call__(self, **kwargs):
        return await self.judge(**kwargs)

    async def judge(self, **kwargs):
        prompt = self.prompt_template.format(**kwargs)

        # DÃ¹ng logprob náº¿u Ä‘Ã¡nh giÃ¡ sá»‘
        logprobs = await self._logprob_probs(prompt)
        score = self.aggregate_score(logprobs)
        return score

    # ======================================================================
    # ðŸ”¥ Láº¤Y LOGPROB ÄÃšNG CHUáº¨N GIá»NG NHÆ¯ DEMO GOOGLE NGÃ€Y 15-11-2024
    # ======================================================================
    async def _logprob_probs(self, prompt_text: str) -> dict:
        """
        Tráº£ vá» dict: token â†’ probability
        Chá»‰ nháº­n token dáº¡ng sá»‘ (digit).
        """

        config = GenerateContentConfig(
            temperature=0,
            max_output_tokens=1,
            response_logprobs=True,
            logprobs=20,      # giá»‘ng code Colab
            seed=0,
        )

        # Äá»‹nh dáº¡ng contents Ä‘Ãºng chuáº©n GenAI
        contents = [
            {
                "role": "user",
                "parts": [
                    {"text": prompt_text}
                ]
            }
        ]

        try:
            response = await self.client.aio.models.generate_content(
                model=self.model_name,
                contents=contents,
                config=config,
            )
        except Exception as e:
            print("âŒ Logprob API error:", e)
            return {}

        # KhÃ´ng cÃ³ logprobs_result
        if (
            not response.candidates 
            or not response.candidates[0].logprobs_result
        ):
            return {}

        lp = response.candidates[0].logprobs_result

        # Token Ä‘áº§u tiÃªn Ä‘Æ°á»£c model sinh ra
        top_candidates = lp.top_candidates[0].candidates

        probs = {}

        for cand in top_candidates:
            token = cand.token.strip()
            prob = math.exp(cand.log_probability)

            # Chá»‰ nháº­n token dáº¡ng sá»‘
            if token.isdigit():
                probs[token] = prob

        return probs

    # ======================================================================
    # ðŸ”¥ AGGREGATE SCORE 0â€“100
    # ======================================================================
    def _aggregate_0_100_score(self, score: dict) -> float:
        """
        TÃ­nh expected value cá»§a phÃ¢n phá»‘i:
            sum(p_i * i)
        Chá»‰ nháº­n i tá»« 0â€“100.
        """

        if not score:
            return None

        total_p = 0
        weighted_sum = 0

        for token, prob in score.items():
            try:
                num = int(token)
            except ValueError:
                continue

            if 0 <= num <= 100:
                weighted_sum += num * prob
                total_p += prob

        # náº¿u phÃ¢n phá»‘i quÃ¡ loÃ£ng (model khÃ´ng tá»± tin)
        if total_p < 0.25:
            return None

        return weighted_sum / total_p
