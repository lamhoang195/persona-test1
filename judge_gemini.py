import os
import math
import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig
import google.generativeai as genai

# # config = setup_credentials()
# # genai.configure(api_key=config.gemini_api_keys[0])

# try:
#     PROJECT_ID = "YOUR-PROJECT-ID"  # ðŸ‘ˆ THAY THáº¾ Báº°NG PROJECT ID Cá»¦A Báº N
#     LOCATION = "us-central1"       # ðŸ‘ˆ THAY THáº¾ Báº°NG REGION (vÃ­ dá»¥: us-central1)
    
#     vertexai.init(project=PROJECT_ID, location=LOCATION)
# except Exception as e:
#     print(f"Lá»—i khi khá»Ÿi táº¡o Vertex AI. Báº¡n Ä‘Ã£ cÃ i Ä‘áº·t 'gcloud' vÃ  xÃ¡c thá»±c chÆ°a?")
#     print(f"Cháº¡y: gcloud auth application-default login")
#     print(f"Lá»—i gá»‘c: {e}")
#     # ThoÃ¡t náº¿u khÃ´ng thá»ƒ khá»Ÿi táº¡o
#     exit(1)

class GeminiJudge:
    def __init__(self, model: str, prompt_template: str, eval_type: str = "0_100"):
        self.model_name = model
        self.model = GenerativeModel(model_name=self.model_name)
        self.prompt_template = prompt_template
        assert eval_type in ["0_100", "0_10", "binary", "binary_text"], f"Unsupported eval_type: {eval_type}"
        self.eval_type = eval_type

        # Chá»n hÃ m tá»•ng há»£p (aggregate) phÃ¹ há»£p vá»›i loáº¡i Ä‘Ã¡nh giÃ¡
        if self.eval_type == "0_100":
            self.aggregate_score = self._aggregate_0_100_score
        elif self.eval_type == "0_10":
            self.aggregate_score = self._aggregate_0_10_score
        elif self.eval_type == "binary":
            self.aggregate_score = self._aggregate_binary_score
        elif self.eval_type == "binary_text":
            self.aggregate_score = self._aggregate_binary_text_score

    async def __call__(self, **kwargs):
        return await self.judge(**kwargs)

    async def judge(self, **kwargs):
        # Chuyá»ƒn Ä‘á»•i 'content' thÃ nh 'parts' theo cÃº phÃ¡p cá»§a Vertex AI
        prompt_text = self.prompt_template.format(**kwargs)
        contents = [{"role": "user", "parts": [{"text": prompt_text}]}]

        if self.eval_type == "binary_text":
            response_text = await self._query_full_text(contents)
            return self.aggregate_score(response_text)
        else:
            logprobs = await self._logprob_probs(contents)
            return self.aggregate_score(logprobs)

    async def _logprob_probs(self, contents) -> dict:
        generation_config = GenerationConfig(
            max_output_tokens=1,     # Chá»‰ láº¥y 1 token
            temperature=0,           # Äá»ƒ káº¿t quáº£ mang tÃ­nh quyáº¿t Ä‘á»‹nh
            response_logprobs=True,  # Báº­t logprobs cho token ÄÃƒ CHá»ŒN
            logprobs=20,             # YÃªuCáº§u TOP 20 token thay tháº¿
            seed=0                   # Äáº·t seed Ä‘á»ƒ káº¿t quáº£ cÃ³ thá»ƒ tÃ¡i táº¡o
        )
        try:
            # Gá»i API Vertex AI báº±ng generate_content_async
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config=generation_config
            )
            
            # PhÃ¢n tÃ­ch cáº¥u trÃºc tráº£ vá» cá»§a Vertex AI
            # [0] Ä‘áº§u tiÃªn vÃ¬ chÃºng ta chá»‰ yÃªu cáº§u 1 token (max_output_tokens=1)
            logprobs_data = response.candidates[0].logprobs_result.token_logprobs[0]
            
            # logprobs_data.top_logprobs lÃ  má»™t danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng TokenLogprob
            top_logprobs = logprobs_data.top_logprobs

        except (Exception, IndexError, AttributeError) as e:
            print(f"âš ï¸ Lá»—i khi gá»i hoáº·c phÃ¢n tÃ­ch Vertex AI logprobs: {e}")
            return {}

        result = {}
        for el in top_logprobs:
            # el.token lÃ  chuá»—i token (vÃ­ dá»¥: "YES", "NO", "10")
            # el.logprob lÃ  Ä‘iá»ƒm log-probability (float, vÃ­ dá»¥: -0.01)
            # Cáº§n .strip() Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ khoáº£ng tráº¯ng thá»«a
            token = el.token.strip()
            if token: # Äáº£m báº£o token khÃ´ng rá»—ng
                result[token] = float(math.exp(el.logprob))
        
        return result

    async def _query_full_text(self, contents: list) -> str:
        """
        CHANGED: Cáº­p nháº­t Ä‘á»ƒ dÃ¹ng self.model cá»§a Vertex AI vÃ  nháº­n 'contents'.
        """
        try:
            response = await self.model.generate_content_async(
                contents=contents,
                generation_config={"temperature": 0}
            )
            return response.text.strip()
        except Exception as e:
            print(f"âš ï¸ Vertex AI full text error: {e}")
            return ""

    def _aggregate_0_100_score(self, score: dict) -> float:
        total, sum_ = 0, 0
        for key, val in score.items():
            try:
                int_key = int(key)
            except ValueError:
                continue
            if not (0 <= int_key <= 100):
                continue
            sum_ += int_key * val
            total += val
        return None if total < 0.25 else sum_ / total

    def _aggregate_0_10_score(self, score: dict) -> float:
        if "REFUSAL" in score and score["REFUSAL"] > max(score.get(str(i), 0) for i in range(10)):
            return None
        total, sum_ = 0, 0
        for key, val in score.items():
            try:
                int_key = int(key)
            except ValueError:
                continue
            if not (0 <= int_key <= 9):
                continue
            sum_ += int_key * val
            total += val
        return None if total < 0.25 else sum_ / total

    def _aggregate_binary_score(self, score: dict) -> float:
        yes_prob = score.get("YES", 0.0)
        no_prob = score.get("NO", 0.0)
        refusal_prob = score.get("REFUSAL", 0.0)
        if refusal_prob > yes_prob and refusal_prob > no_prob:
            return None
        denominator = yes_prob + no_prob
        return None if denominator < 0.25 else yes_prob / denominator

    def _aggregate_binary_text_score(self, response_text: str) -> float | None:
        if "<answer>REFUSAL</answer>" in response_text:
            return None
        elif "<answer>NO</answer>" in response_text:
            return 0
        elif "<answer>YES</answer>" in response_text:
            return 1
        return None

    async def __call__(self, **kwargs):
        return await self.judge(**kwargs)